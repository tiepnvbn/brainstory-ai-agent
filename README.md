# ğŸ§  BrainStory AI Agent

**Intelligent User Story Generator with Enterprise Integration**

BrainStory AI Agent lÃ  má»™t cÃ´ng cá»¥ AI thÃ´ng minh giÃºp táº¡o User Stories chi tiáº¿t tá»« yÃªu cáº§u nghiá»‡p vá»¥, tÃ­ch há»£p vá»›i GitHub Enterprise vÃ  Rally Ä‘á»ƒ cung cáº¥p context phong phÃº vÃ  chÃ­nh xÃ¡c.

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/streamlit-v1.28+-red.svg)
![LangChain](https://img.shields.io/badge/langchain-latest-green.svg)
![ChromaDB](https://img.shields.io/badge/chromadb-vector--database-purple.svg)

## ğŸŒŸ TÃ­nh nÄƒng chÃ­nh

### ğŸ¯ **AI-Powered User Story Generation**
- Táº¡o User Stories chi tiáº¿t tá»« mÃ´ táº£ ngáº¯n gá»n
- Sá»­ dá»¥ng local AI models (Ollama) Ä‘á»ƒ Ä‘áº£m báº£o báº£o máº­t
- Fallback mode thÃ´ng minh khi khÃ´ng cÃ³ AI models

### ğŸ¢ **Enterprise Integration**
- **GitHub Enterprise**: Káº¿t ná»‘i vá»›i Cox Automotive GitHub Enterprise (ghe.coxautoinc.com)
- **Rally**: TÃ­ch há»£p vá»›i Rally Project Management (rally1.rallydev.com)
- **Secure**: Táº¥t cáº£ dá»¯ liá»‡u Ä‘Æ°á»£c xá»­ lÃ½ local

### ğŸ’¾ **Vector Database**
- ChromaDB Ä‘á»ƒ lÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m context
- Semantic search cho dá»¯ liá»‡u liÃªn quan
- Persistent storage cho learning liÃªn tá»¥c

### ğŸ” **Smart Context Enhancement**
- Tá»± Ä‘á»™ng thu tháº­p context tá»« GitHub issues, PRs, repository info
- Láº¥y dá»¯ liá»‡u tá»« Rally user stories, features, defects
- Vector search trong historical data

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
BrainStory AI Agent
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py              # Streamlit web interface
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_handler.py       # AI processing vá»›i Ollama
â”‚   â”œâ”€â”€ data_connector.py    # GitHub & Rally integration
â”‚   â””â”€â”€ vector_db.py         # ChromaDB vector database
â”œâ”€â”€ connectors/
â”‚   â”œâ”€â”€ github_connector.py  # GitHub API wrapper
â”‚   â”œâ”€â”€ rally_connector.py   # Rally API wrapper
â”‚   â””â”€â”€ slack_connector.py   # Slack integration (future)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start_vector_db.py   # Vector database setup
â”‚   â”œâ”€â”€ populate_demo_data.py # Demo data population
â”‚   â””â”€â”€ run_agent.py         # Main runner script
â””â”€â”€ chroma_db/               # Vector database storage
```

## ğŸš€ Quick Start

### 1. **Clone Repository**
```bash
git clone <repository-url>
cd brainstory_ai_agent
```

### 2. **Setup Python Environment**
```bash
# Táº¡o virtual environment
python -m venv venv

# Activate environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. **Environment Configuration**
Táº¡o file `.env` trong thÆ° má»¥c gá»‘c:

```env
# GitHub Enterprise Configuration
GITHUB_URL=https://ghe.coxautoinc.com
GITHUB_TOKEN=your_github_enterprise_token

# Rally Configuration  
RALLY_API_KEY=your_rally_api_key

# Slack (Optional)
SLACK_TOKEN=your_slack_token
```

### 4. **Setup Vector Database**
```bash
# Khá»Ÿi táº¡o ChromaDB
python scripts/start_vector_db.py

# Populate demo data (optional)
python scripts/populate_demo_data.py
```

### 5. **Setup Local AI (Optional but Recommended)**
```bash
# Install Ollama
# Windows: Download tá»« https://ollama.ai
# macOS: brew install ollama

# Pull AI models (chá»n má»™t trong cÃ¡c models sau)
ollama pull llama3.2:1b      # Lightest (1.3GB)
ollama pull qwen2:1.5b       # Fast & efficient (0.9GB)
ollama pull gemma2:2b        # Google model (1.6GB)
ollama pull phi3:mini        # Microsoft model (2.3GB)
```

### 6. **Run Application**
```bash
# Start Streamlit app
streamlit run app/main.py

# Hoáº·c sá»­ dá»¥ng script runner
python scripts/run_agent.py
```

ğŸŒ **Open browser**: http://localhost:8501

## ğŸ“– HÆ°á»›ng dáº«n sá»­ dá»¥ng

### ğŸ¯ **Tab 1: Táº¡o User Story**

1. **Nháº­p yÃªu cáº§u**: MÃ´ táº£ ngáº¯n gá»n feature cáº§n táº¡o User Story
2. **Chá»n context source**: 
   - GitHub Enterprise repository
   - Rally workspace/project
   - Hoáº·c khÃ´ng sá»­ dá»¥ng context
3. **Generate**: AI sáº½ táº¡o User Story chi tiáº¿t vá»›i:
   - User Story format chuáº©n
   - Acceptance Criteria
   - Priority vÃ  Story Points estimate
   - Dependencies (náº¿u cÃ³)

**VÃ­ dá»¥ input**: "Táº¡o tÃ­nh nÄƒng Ä‘Äƒng nháº­p báº±ng Google OAuth"
**Output**: User Story Ä‘áº§y Ä‘á»§ vá»›i AC, technical considerations, security requirements

### ğŸ“Š **Tab 2: GitHub Enterprise Data**

1. **Repository Explorer**: 
   - Nháº­p `owner/repository-name`
   - Xem repository info, README, main language
2. **Issues & PRs**: Browse recent issues vÃ  pull requests
3. **File Structure**: KhÃ¡m phÃ¡ cáº¥u trÃºc project

### ğŸ¢ **Tab 3: Rally Data**

1. **User Stories**: Xem cÃ¡c User Stories trong workspace/project
2. **Features**: Browse cÃ¡c Features Ä‘ang phÃ¡t triá»ƒn
3. **Defects**: Theo dÃµi bugs vÃ  issues tá»« Rally

### ğŸ” **Tab 4: Vector Search**

1. **Semantic Search**: TÃ¬m kiáº¿m trong historical data
2. **Filter by Source**: GitHub, Rally, hoáº·c táº¥t cáº£
3. **Relevance Scoring**: Káº¿t quáº£ Ä‘Æ°á»£c sáº¯p xáº¿p theo Ä‘á»™ liÃªn quan

## ğŸ”§ Configuration

### GitHub Enterprise Setup

1. **Generate Personal Access Token**:
   - ÄÄƒng nháº­p vÃ o https://ghe.coxautoinc.com
   - Settings â†’ Developer Settings â†’ Personal Access Tokens
   - Generate token vá»›i scopes: `repo`, `read:org`

2. **Add to .env**:
   ```env
   GITHUB_URL=https://ghe.coxautoinc.com
   GITHUB_TOKEN=ghp_your_token_here
   ```

### Rally API Setup

1. **Get API Key**:
   - ÄÄƒng nháº­p Rally â†’ Profile â†’ API Keys
   - Generate new API key

2. **Add to .env**:
   ```env
   RALLY_API_KEY=your_rally_api_key_here
   ```

### Ollama Models Configuration

**Recommended models** (theo thá»© tá»± Æ°u tiÃªn):

| Model | Size | Speed | Quality | Best For |
|-------|------|-------|---------|----------|
| `llama3.2:1b` | 1.3GB | âš¡âš¡âš¡ | â­â­â­ | Quick responses |
| `qwen2:1.5b` | 0.9GB | âš¡âš¡âš¡ | â­â­â­â­ | Balanced |
| `gemma2:2b` | 1.6GB | âš¡âš¡ | â­â­â­â­ | Google quality |
| `phi3:mini` | 2.3GB | âš¡âš¡ | â­â­â­â­â­ | Microsoft, highest quality |

## ğŸ› ï¸ Development

### Project Structure
```
â”œâ”€â”€ app/                    # Frontend Streamlit app
â”œâ”€â”€ core/                   # Core business logic
â”œâ”€â”€ connectors/            # External service integrations  
â”œâ”€â”€ scripts/               # Utility scripts
â”œâ”€â”€ chroma_db/            # Vector database storage
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env                  # Environment variables
â””â”€â”€ README.md            # This file
```

### Adding New Features

1. **New Connector**: Add to `connectors/` folder
2. **Core Logic**: Extend `core/` modules
3. **UI Components**: Update `app/main.py`
4. **Vector DB**: Use `core/vector_db.py` for storage

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GITHUB_URL` | Yes | GitHub Enterprise URL |
| `GITHUB_TOKEN` | Yes | GitHub Personal Access Token |
| `RALLY_API_KEY` | Yes | Rally API Key |
| `SLACK_TOKEN` | No | Slack Bot Token (future feature) |

## ğŸ› Troubleshooting

### Common Issues

**1. Ollama Models Not Found**
```bash
# Check Ollama service
ollama list

# Pull missing models
ollama pull llama3.2:1b
```

**2. GitHub API Connection Error**
- Verify `GITHUB_TOKEN` cÃ³ quyá»n truy cáº­p repository
- Check GitHub Enterprise URL format
- Ensure token chÆ°a expired

**3. Rally API Authentication Error**
- Verify `RALLY_API_KEY` in .env file
- Check Rally permissions cho workspace/project
- Test connection vá»›i Rally web interface

**4. ChromaDB Issues**
```bash
# Reset vector database
rm -rf chroma_db/
python scripts/start_vector_db.py
```

### Debug Mode

```bash
# Enable debug logging
export DEBUG=1
streamlit run app/main.py

# Or run debug scripts
python scripts/debug_rally.py
python scripts/test_github_connection.py
```

## ğŸ“Š Performance

### System Requirements
- **RAM**: 4GB minimum, 8GB recommended
- **Storage**: 2GB for Ollama models + 500MB for app
- **Network**: Stable connection cho GitHub/Rally APIs

### Optimization Tips
1. **Use smaller AI models** cho faster responses
2. **Enable vector DB caching** Ä‘á»ƒ giáº£m API calls
3. **Limit context data** Ä‘á»ƒ trÃ¡nh prompt quÃ¡ dÃ i

## ğŸ”’ Security

### Data Privacy
- âœ… **Local AI Processing**: Ollama models cháº¡y local
- âœ… **No External AI APIs**: KhÃ´ng gá»­i data Ä‘áº¿n OpenAI/Claude
- âœ… **Encrypted Storage**: ChromaDB local storage
- âœ… **Secure Tokens**: Environment variables cho credentials

### Best Practices
1. **Rotate API tokens** Ä‘á»‹nh ká»³
2. **Use limited scope tokens** (chá»‰ cáº§n thiáº¿t)
3. **Don't commit .env** file vÃ o git
4. **Regular security updates** cho dependencies

## ğŸ“ˆ Roadmap

### V1.1 (Next Release)
- [ ] Slack integration cho notifications
- [ ] Advanced filtering cho vector search  
- [ ] Bulk User Story generation
- [ ] Export functionality (PDF, DOCX)

### V1.2 (Future)
- [ ] JIRA integration
- [ ] Custom AI model training
- [ ] Team collaboration features
- [ ] Analytics dashboard

## ğŸ¤ Contributing

1. **Fork** the repository
2. **Create feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit changes**: `git commit -m 'Add amazing feature'`
4. **Push to branch**: `git push origin feature/amazing-feature`
5. **Open Pull Request**

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support

- **Issues**: GitHub Issues tracker
- **Documentation**: This README + inline code comments
- **Team**: Cox Automotive Development Team

---

**Made with â¤ï¸ for Cox Automotive by BrainStory AI Team**

ğŸš€ **Happy User Story Generation!** ğŸš€